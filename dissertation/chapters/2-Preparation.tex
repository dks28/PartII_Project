\chapter{Preparation}

In this chapter, I first develop the background of the computational problem of clustering 
directed graphs using spectral methods, by further explaining the well-studied methodology 
applicable to undirected graphs. Next, I introduce the two algorithms that have been developed to 
solve the problem, and describe how their respective methodologies contribute to this aim. 
Furthermore, I elaborate on the random-graph models that have been developed in conjunction with 
these algorithms, and how their usage for testing the algorithms is not entirely representative of 
real-world problems, which will help explain and justify the interest behind this project. 

\section{Clustering}

This project concerns itself with one specific clustering problem. In general, however, clustering
is applicable to many more kinds of data than just graphs, for which many different algorithms have 
been developed to suit different needs. Perhaps the most common algorithm that clusters general, 
$m$-dimensional data is Lloyd's $k$-means clustering algorithm \cite{lloyd}.

\subsection{$k$-Means Clustering}
Lloyd's  algorithm is very widely used and fairly straightforward to 
understand. Given a set $D$ of points in $m$ dimensions, and an integer $k$, it partitions $D$ 
into $k$ cells of nearby elements. It is presented in Algorithm \ref{algorithm:lloyd}.

It is, of course, important to note that the clusters returned by Lloyd's algorithm are only 
locally optimal. This, however, can be counteracted by running the algorithm several times with 
different initialisations of the centroids. Lloyd's algorithm operates on general data, and by 
terminating the algorithm at approximate, instead of absolute convergence or after a fixed number 
of iterations yields a fast run-time for the generally speaking NP-hard computational 
problem. Indeed, Lloyd's algorithm works very well empirically.

\begin{algorithm}
	\caption{Lloyd's $k$-Means Clustering}
	\label{algorithm:lloyd}

	\SetKwInOut{Require}{require}\SetKwInOut{Yield}{yield}
	\SetKwFunction{RandChoice}{random\_choice}
	\Require{Set $D$ of $m$-dimensional co\"ordinates, integer $k$}
	\Yield{Partition of $D$ with $k$ cells.}
	\BlankLine
		\tcp{Initialise centroids to arbitrary members of $D$}
		$C \longleftarrow$ \RandChoice$(k, D)$\;
		\While{set $C$ has not converged}{
			\tcp{Find data-centroid assignments}
			$\mathbb{C}\longleftarrow\{\mathbf{c}\mapsto\varnothing:\mathbf{c}\in C\}$\;
			\ForEach{$\mathbf{d} \in D$}{
				$\mathbf{c} \coloneqq \arg\min_{\mathbf{p}\in C}(\|\mathbf{p}-
				\mathbf{d}\|_2)$\;
				$\mathbb{C}(\mathbf{c})\longleftarrow \mathbb{C}(\mathbf{c}) \cup \{\mathbf{d}\}$\;
			}
			\tcp{Update positions of centroids to average of their respective clusters}
			$C \longleftarrow 
			\{\sum_{\mathbf{d}\in\mathbb{C}(\mathbf{c})}\mathbf{d} /|\mathbb{C}(\mathbf{c})|:\mathbf{c}\in C\}$\;
		}

		\KwRet{$\mathbb C$}
	
\end{algorithm}

These properties of Lloyd's algorithm mean that it would be convenient to use it as a basis for
algorithms clustering the vertices of a graph. To this end, one can consider a particular 
representation of an undirected graph known as its \emph{Laplacian}. 

\subsection{Spectral Methods}

\subsubsection{Undirected Graphs And Their Laplacians}
Consider some undirected graph $G = (V, E)$ with adjacency matrix $A$. Suppose that $|V| = n$
such that $A$ is of dimension $n \times n$, and notice that $A$ is symmetric since $G$ is 
undirected. Now, consider the diagonal matrix $D$ that has $D_{i,i} = d_i$, where $d_i$ is the 
degree of vertex $i \in V$. Take 
$$
	\mathcal{L} \coloneqq D - A,
$$
the Laplacian of $G$, we note that $\mathcal{L}$ is still symmetric. This means that the 
eigenvalues associated to its eigenvectors are all real. Indeed, suppose that $G$ is disconnected
with $k$ connected components. Then consider, for any one (say $G_1$) of these connected components
the vector $e$ defined by $e_i = 1[i \in G_1]$. The vector $e$ is an eigenvector of $\mathcal{L}$ 
with eigenvalue 0, and it is a well-known result that the algebra\"ic multiplicity of 0 in the Lapalcian's characteristic polynomial is the number of connected components in the graph \cite{Chung:1997}.

\subsubsection{Spectral Clustering}
In the setting of undirected graphs, the notion of similarity between two graph vertices is roughly 
equivalent to the question of how well-connected the vertices are. In the extreme, consider the case
where we wish to find $k$ clusters of graph nodes, and suppose again that the graph happens to have 
exactly $k$ connected components. Then, with our notion of vertex similarity, the $k$ clusters 
found by a reasonable algorithm should return the connected components of the graph. Therefore, 
consider the eigenpairs $(\lambda_i, e_i)$ of the Laplacian in this scenario, where $|\lambda_1| 
\leq |\lambda_2| \leq \hdots \leq |\lambda_n|$. We know that $\forall 1\leq i \leq k$, $\lambda_i 
=0$ and for all other $i$, $\lambda_i \neq 0$. Hence, by choosing the eigenvectors corresponding
to the lowest $k$ eigenvalues, consider the $n$ $k$-dimensional points $p_1 \hdots p_n$ obtained by
setting $(p_j)_i = (e_i)_j$. These points will form the $k$ canonical basis vectors for $k$ 
dimensions, for any two vertices $u,v$ in the same connected component of $G$ will lie on the same 
point, meaning that Lloyd's algorithm will clearly quickly recover the connected components very 
quickly.

In the more general setting where the graph is connected, it is not obvious that this method should 
work. However, it should be noted that Davis and Kahan 
established in 1969 that modifying a matrix insignifcantly does not perturb the space spanned by 
its eigenvectors significantly \cite{daviskahan}. This has the following significance for graph clustering: If we 
consider any graph to have an underlying, disconnected graph with $k$ connected compoonents, which
has been modified by adding (or perhaps removing) noisy edges, then the original disconnected graph
(which we take to be our desired clustering) can be recovered by applying the method described 
above to the Laplacian of the noisy graph.

This method is known as the \emph{spectral clustering} algorithm for graphs. It works because the Laplacian captures the important 
information about node connectivity, and so do its eigenvectors. However, it relies on the fact that
the eigenvalues of the Laplacian are real, which was guaranteed by the fact that the Laplacian is 
symmetric. This foreshadows one of the difficulties with spectral clustering methods for directed 
graphs, the adjacency matrices of which are not symmetric.

\subsection{Directional Communities and Clustering}

Besides the difficulty mentioned above, the problem of clustering directed graphs according to 
vertex similarity suffers another impairment: The notion of what made vertices of undirected 
graphs was simple enough, and made for an easy way of representing the graph in a format amenable 
to Lloyd's algorithm. However, since directed graphs have no equivalent notion of connectivity, 
this notion can no longer be used in this setting. This raises the question of how one should 
think about communities in directed graphs. 

\subsubsection{Directional Communities}
A first, simplistic, approach to remedying these issues is to remove the directional information 
from the graph and proceed by clustering it exactly as before. However, this misses the point of 
the task at hand. Consider, for example, a network that represents global trade. By removing the 
information of what directions goods flow in, we could not obtain clusters that take into account 
exporting and importing nations, attributes which should be of particular interest when  
considering what makes different countries similar with respect to trade. 

Instead of the extent of connectedness between two groups of vertices, therefore, a notion of 
`directional communities' emerged, in which the interactions between nodes of different 
commmunities became important, rather than the interactions of nodes within one cluster \cite{lucapaper, disimpaper}. 
This is particularly interesting when considering bipartite graphs. Consider for example a data 
set detailing the membership of a set of words in a set of texts, and the graph representing this 
membership relation. One can measure the similarity of texts by the words they contain, or the 
similarity of words by the texts in which they occur. Thus clustering the graphs with respect to the sending and receiving behaviours of nodes allows for helpful insights in machine learning. 

\subsubsection{The DiSim Algorithm}
This project considers two main algorithms that have been developed to deal with such directional 
communities. The first of these was developed by Rohe et al.\ \cite{disimpaper}; called DiSim. It
is based closely on classical spectral clustering.

The algorithm first construct a so-called `regularized graph Laplacian', which, given the 
adjacency matrix $A$, defined as 
$$
	L \coloneqq O^{-\sfrac{1}{2}}\times A\times P^{-\sfrac{1}{2}} 
$$
where $O$ and $P$ are diagonal matrices storing each node's out- and in-degree respectively, 
which reweight the graph so that heavily connected nodes do not dominate. From this construction, it 
computes, instead of the eigenvectors of this Laplacian (which would not correspond to real 
eigenvalues, and so could not be ordered), the left and right \emph{singular} vectors which record 
the sending and receiving behaviours of the graph's nodes, respectively. 

The singular  values behave analogously to the eigenvalues 
from before, but in DiSim, the `top' singular vectors are selected to base a clustering upon. 
This is because of the slightly different construction of $L$ in this case than $\mathcal{L}$ 
before. Another modification this algorithm makes is that it allows its user to cluster directed 
graphs particular with respect to `sending' or `receiving communities' by choosing which singular vectors are used. 

When the sending and receiving communities are taken to co\"incide, this can cause some confusion.
However, for that, less general notion of directional communities, Cucuringu et al.\ have developed
another algorithm \cite{lucapaper}.

\subsubsection{Hermitian Spectral Clustering}
In the development of this next algorithm (which I shall call Herm), another approach was taken 
that also exploits 
having real eigenvalues to work with. This approach was to represent the graph, instead 
of by a real adjacency matrix, by a complex-valued one. It is presented in Algorithm 
\ref{algorithm:herm}. This approach allows the preservation of the directional information whilst 
also retaining a simple representation of the graph. 
\begin{algorithm}
	\caption{Hermitian Spectral Clustering (Herm) \label{algorithm:herm}}
	\SetKwInOut{Require}{require}\SetKwInOut{Yield}{yield}
	\Require{Adjacency Matrix $A$ of graph $G$, integer $k$, $\epsilon \in \mathbb{R}^+$}
	\Yield{Partition of $G$ into directional communities}
	\BlankLine
	\tcp{Compute Hermitian representation of $G$}
	$A_\mathrm{Herm} \coloneqq \imath \cdot A - \imath\cdot A^T$\;
	$A_\mathrm{Herm} \longleftarrow D^{-\sfrac12} A_\mathrm{Herm} D^{-\sfrac12}$ where $D$ is
	the diagonal matrix storing the sum of in- and out-degrees\;
	$\{(\lambda_i, e_i)\} \longleftarrow$\ those eigenpairs of $A_\mathrm{Herm}$ such that 
	$|\lambda_i| > \epsilon$\;
	\tcp{Eigenvectors are complex, however, so represent graph as real data}
	$P \longleftarrow \sum_i e_i \times e_i^H$\;
	\KwRet{Result of applying Lloyd's algorithm to the rows of $P$, with $k$ clusters}
\end{algorithm}

Here, $\imath$ denotes the imaginary unit; $\imath \coloneqq \sqrt{-1}$. Given a 
matrix $X$, its transpose is denoted $X^T$ and its conjugate transpose $X^H$. Lastly, the matrix $P
$ that is constructed as part of the algorithm is real, which is guaranteed by properties 
of $A_\mathrm{Herm}$ that are not essential to understanding the algorithm.

To understand Herm, consider an equivalent definition of 
$A_\mathrm{Herm}$:
$$
	(A_\mathrm{Herm})_{i,j} \coloneqq
	\begin{dcases}
		\imath & i \leadsto j \\
		- \imath & j \leadsto i \\
		0 & \text{otherwise.}
	\end{dcases}
$$
Therefore, $A_\mathrm{Herm}^2$ can be written as follows:
\begin{align*}
	(A_{\mathrm{Herm}}^2)_{i,j} &= \sum_{l} A_{i,l} \cdot A_{l, j} \\
	&=\sum_l \imath \cdot (1[i \leadsto l] - 1[l \leadsto i]) \cdot \imath \cdot 
	(1[l \leadsto j] - 1[j \leadsto l]) \\
	&= \sum_l (1[i \leadsto l]\cdot1[j \leadsto l] + 1[l \leadsto i]\cdot1[l 
	\leadsto j]) - \sum_l (1[i \leadsto l]\cdot1[l \leadsto j] + 1[l \leadsto i]\cdot1[j 
	\leadsto l])
\end{align*}
which means that the matrix $A_\mathrm{Herm}^2$ counts the number of nodes that are either common 
parents or common children of $i$ and $j$ whilst discounting nodes that have differently oriented 
connections to $i$ and $j$, respectively. Since $A_\mathrm{Herm}$ has the same eigenvectors as 
$A_\mathrm{Herm}^2$, $A_\mathrm{Herm}$ also implicitly tracks this.  This explanation has also been given in \cite{lucapaper},
but is crucial to understanding the idea behind Herm.

\section{Supporting Graph Models}

In the development of the algorithms presented above, different models of random digraphs with directional communities have been developed; the purpose of this was to able to evaluate 
the performance of their algorithms aginst a known ground truth. To introduce these, recall two 
basic random-graph models that underly those models.

\subsection{Undirected Random Graphs}

The first is perhaps the most basic model of random graph, the Erd\H{o}s-R\'enyi model $\mathcal{G}(n,p)$ 
taking parameters $n \in \mathbb{N}$ and $p \in [0, 1]$. In a graph $G \sim \mathcal{G}(n,p)$, 
$V(G) = [n]$, and two nodes $i,j$ are connected in $G$ with probability $p$.

A slightly more advanced random-graph-model is the so-called Stochastic Block-Model (SBM). Given
parameters $k, n \in \mathbb{N}$, $p, q \in [0,1]$, a graph sampled from the SBM has $k \cdot n$
nodes, separated in $k$ clusters of $n$ nodes each. Within a cluster, two nodes are connected with
probability $p$, when nodes $i, j$ are in separate clusters, they are connected with probability 
$q$.  

\subsection{Directed Communities With a Directed SBM}

To support the evaluation of Herm, a \emph{directed} stochastic 
block-model (DSBM) has been introduced \cite{lucapaper}. This model is based on the SBM of before, but adds a parameter $\mathcal{F}
\in [k] \times [k] \rightarrow [0,1]$. Let us consider this parameter as a matrix storing, for each
ordered pair $(c_1, c_2)$ of clusters, the probability of an edge between the two clusters being 
oriented from $c_1$ to $c_2$. Notice that therefore, $\mathcal{F}_{i,j} = 1-\mathcal{F}_{j,i}$, and
so $\mathcal{F}_{i,i} = \sfrac{1}{2}$ for any $i$.

The DSBM behaves just like the previous SBM, but then orients all edges in the resulting graph 
according to $\mathcal{F}$. This means that the nature of directional relationships in the graph
is easily configurable by changing the parameter $\mathcal{F}$. This is explained more clearly 
explained in Chapter 3.

The advantage of this model is that it is easily understood and configurable, since only one 
parameter needs to be tuned to give such graphs directional communities. However, 
we should also note its disadvantages: Firstly, it does not allow for varying quantities of 
communication between clusters; between any two clusters, the number of edges concentrates around 
$qn^2$. Secondly, the degrees of all vertices in the graph are highly homogeneous; with high 
probability, each node has degree approximately $pn + 
(k-1) q n$. 

While a model developed in support of DiSim can address 
the second issue, the first issue remains even there; that model is a generalisation of the DSBM, 
the main advantage of which is that it allows for bipartite graphs which is not of particular 
interest for this project. Furthermore, the way to address the homogeneous degree distribution 
here is complicated and requires  fixing the in- and out-degrees of each indivdual vertex, which 
makes working with these `degree-corrected' graphs infeasible. 

\subsection{Real-World Graphs}
This difficulty is significant because many interesting networks in real-life settings 
follow very heterogeneous degree distributions: To return to our previous example, word frequencies
are distributed according to a Zipf distributions in natural languages, which exhibit very 
long power-tails. Another source of examples for such power-tail distributions is the setting of 
research papers; graphs that are formed by adding edges representing citations between to papers 
(so-called citation networks) have also been shown to follow power-tail distributions of vertex 
degrees. 

Indeed, many such networks that grow over time do, including the internet. To model their growth, 
Price developed a random-graph model that utilises a technique known as preferential attachment \cite{price}. 
In this model, the sampled graph grows over time, adding one node at a time which forms edges 
according to some specified distributions, where each edge attaches more probably to vertices that
already have many incoming edges. This graph model is supported by a smoothing parameter $a$ that 
ensures that new vertices can also gain citations, which can be adapted to fit empirically determined
values.

\section{Requirements Analysis}

\subsubsection{Motivations}
It is one aim of this project to evaluate the performace of the existing algorithms on graphs 
that exhibit such power-tail distributions. Little research with such graphs has so far been done
concerning the detection of directional communities and these algorithms have mainly been applied to 
graphs that were sampled from models that would naturally approximte idealised inputs.
This means that there is scientific interest in the renewed evaluation of the algorithms outside of
the control of their respective developers, while also expanding on the experiments done previously.

\subsubsection{Generating Irregular Graphs}
To this end, it will be necessary to be able to produce graphs efficiently which exhibit a 
degree distribution mirroring that of real-world graphs, since the interest in this project lies 
with the applicability to real-world machine-learning challenges, whilst also exhibiting the kind 
of directional communities that define the DSBM. That is, these graphs need to have some known
ground truth about the community structure that expresses itself in the interactions between 
communities. Furthermore, controlling these directional communities should remain easily 
understandable in order to make this study and evaluation of the algorithms reproducible and 
adaptable for new purposes. 

This means that a random model for the generation of such graphs needs to be developed, drawing on
the graph models that already exist to provide a basis for comparison. This model should remain 
understandable and not overly complex to sample from, since the graphs used are not in the focus of
this project. Furthermore, it should be possible to generate these graphs \emph{efficiently} so as
not to slow down the evaluation process drastically.

\subsubsection{Algorithm Performance}
It is besides the interest of this project to analyse how efficiently the algorithms operate, since
the algorithms are formulated from a very high level, so by using partwise solutions to the 
indivdual steps that are as efficient as possible, the algorithms' efficiency may be optimised. 
It is more of interest to determine the quality of any output produced, to which end a performance
criterion needs to be selected and its measurement efficiently implemented. Nevertheless, in the case
that the graphs grow large, since the representaion of the graphs is in matrix form, all steps of the
process will need to utilise quick linear-algebra implementations in order to make testing viable.

It will also be relevant to provide a comparison in performance between operating on graphs sampled
from the heterogeneous model and graphs sampled from the previous models; since the graph models
developed earlier are very suitable for the respective algorithms, the performance on those graphs
will provide an upper bound for the optimal performance of the clustering algorithms. Therefore, 
a correspondence between the previous graph models and the one developed as part of this project 
is required.

\subsubsection{Improving Performance}
In the setting of undirected graphs, modifications to the input graphs have been made to improve the
performance of spectral clustering methods. After obtaining results for the clustering performance 
on the irregular graphs, it will be interesting to evaluate these techniques' applicability to 
the setting of clustering directed graphs with the purpose of recovering directional communities.

\subsubsection{Scientific Validity}
Throughout the experimentation process in this project, the previously conducted experiments are
considered in order to guide which dimensions are explored, and in what sense those experiments can
be expanded upon. The evaluation process has to be guided by a correspondence to
the real world to justify the effort invested and the interest in this poject. This means drawing 
on both shortcomings of previous research, as well as using past techniques and existing ideas to
improve the scientific integrity of the project.

Another factor in ensuring the scientific validity of this project will be to ensure statistical 
significance of the performance results, since the experimentation graphs are largely random. This,
however, will not be difficult to ensure with sufficiently large graphs and multiple experiments 
using different graphs sampled from the same distribution.

\section{Starting Point}
The concepts of graph clustering and random graphs were briefly 
introduced in \emph{Machine Learning and Real-world Data}. In that 
course the problem was approached programmatically rather than with 
spectral methods. The linear algebra thus required for the project was touched on in \emph{Mathematical Methods I} from the Natural Sciences Tripos.

In the specific area of spectral clustering, there have been a few research papers 
concerning the detection of `directional' communities, introducing models of random 
digraphs with community structures, which should help extend undirected random graph models for this project. 
The project will involve implementing and refining algorithms presented in previous research. 
Furthermore, there is some pre\"existing literature on regularising undirected graphs for 
the purpose of clustering, 
from which I will draw a starting point for the corresponding 
parts of the project.
